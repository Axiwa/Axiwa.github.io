<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <meta name="description" content="Silent site" />
  

  
  
  
  
  
  
  <title>CS440 Rendering Engine | Azure</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="基于PBRT的离线渲染引擎，基本框架是Nori. What we have done in this course and project is to extend this basic renderer to support more full-fledged physically-based lighting&#x2F;integrating&#x2F;bsdf functions... The technica">
<meta property="og:type" content="article">
<meta property="og:title" content="CS440 Rendering Engine">
<meta property="og:url" content="http://axiwa.github.io/2023/04/02/cs440/index.html">
<meta property="og:site_name" content="Azure">
<meta property="og:description" content="基于PBRT的离线渲染引擎，基本框架是Nori. What we have done in this course and project is to extend this basic renderer to support more full-fledged physically-based lighting&#x2F;integrating&#x2F;bsdf functions... The technica">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/proposal.jpg">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/sky.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/final.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/modeling.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/text_ref.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/textrec_ref.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/homo.jpg">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/sphere_ref.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/room_ref.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/grassland.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/sphere_blender.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/sphere_two.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/instance.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/bvh.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/memory_peak.png">
<meta property="og:image" content="http://axiwa.github.io/2023/04/images/memory_render.png">
<meta property="article:published_time" content="2023-04-01T16:00:00.000Z">
<meta property="article:modified_time" content="2024-03-07T09:23:25.329Z">
<meta property="article:author" content="Axiwa">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://axiwa.github.io/2023/04/images/proposal.jpg">
  
    <link rel="alternative" href="https://axiwa.github.io" title="Azure" type="application/atom+xml">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  

  
  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script>
<meta name="generator" content="Hexo 5.4.2"></head>
<body class="home blog custom-background custom-font-enabled single-author">
  <div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="Azure" rel="home">Azure</a>
      </h1>
      
        <h2 class="site-description hitokoto"></h2>
        Silent site
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">MENU</button>
            <a class="assistive-text" href="/#content" title="JUMP TO">JUMP TO/a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives">Archives</a></li>
                
                </ul>
            </div>
    </nav>
</header>

      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main"><article id="post-cs440" class="post-cs440 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title article-title">
      CS440 Rendering Engine
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://axiwa.github.io/2023/04/02/cs440/" data-id="clth0sv6t0006xzcudfidh599" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>基于<a
target="_blank" rel="noopener" href="https://pbr-book.org/">PBRT</a>的离线渲染引擎，基本框架是<a
target="_blank" rel="noopener" href="http://rgl.epfl.ch/software/Nori2">Nori</a>.</p>
<p>What we have done in this course and project is to extend this basic
renderer to support more full-fledged physically-based
lighting/integrating/bsdf functions...</p>
<p>The technical details in this passage may not be perfect.</p>
<span id="more"></span>
<p>Final project was to choose several features from many choices and
realize them. What I chose were modeling using Blender, Texture,
Homogeneous participating media and Object instancing.</p>
<h1 id="motivation">Motivation</h1>
<p>A damaged, decaying humanoid machine next to a grassy hillside. I
would like to show the loop of death and rebirth using a vibrant scene
next to a discarded robot. Butterfly also means rebirth in some
culture.</p>
<p>Motivational image: <img src="../../images/proposal.jpg" /></p>
<p><em>Tales from the Loop</em> by Simon Stalenhag</p>
<p><img src="../../images/sky.png" /></p>
<p><em>Castle in the Sky</em> by Tokuma Shoten</p>
<h1 id="final-render">Final Render</h1>
<p><img src="../../images/final.png" /></p>
<h1 id="feature-1-3d-mesh-design">Feature 1 3D Mesh Design</h1>
<p><strong>Description</strong></p>
<p>I used the image from animation to model 3D meshes in Blender and
gave them a pose. The mesh that I modeled are the robot and grass, and a
tree that is used to generate god ray but not presents in the scene.</p>
<p><img src="../../images/modeling.png" /> <img
src="../../images/pose.png" /></p>
<h1 id="feature-2-textures">Feature 2 Textures</h1>
<p><strong>Description</strong></p>
<p>Without textures we cannot present a colorful world. The basic idea
is that the texture uses the image's RGB information to give our BSDF a
specific albedo. In blender, if we uses a UV mapping to let the object
know which part of an image its vertices should be mapped to, it will
write the corresponding UV coordinates while exporting. UV coordinates
are between <span class="math inline">\([0, 1] \times [0,1]\)</span>,
which shows the relative location of a point of an image that each
vertex is binded. When we evaluate or sample the scattering behavior at
the intersection, the UV coorinates have been loaded and recorded in the
texture coordinates of mesh so we use the color at that point in the
picture instead of an default albedo.</p>
<p><strong>Design choice</strong></p>
<p>Here we only consider the 2D (u, v) mapping. Since the UV coordinates
are actually "portion" between 0 and 1, we need to use this value and
the size of the reference picture to get the absolute coordinate in
it.</p>
<p><code>$$ \begin&#123;aligned&#125; x = u * width \\ y = v * height \end&#123;aligned&#125; $$</code></p>
<p>We create a <strong>Texture</strong> class to store the image
information, including the name, size and the address of the imported
image. The public methods includes the constructor which receives a path
and load the corresponding image, and <code>getTexel</code> to access
the texel given UV coordinates.</p>
<p>We use the <code>stbi_image</code> library to read the image.
<code>stbi_load</code> method receives the path of the file (which we
preprocess using <code>getFileResolver()</code> of <code>nori</code>)
and the channels we expect, then returns the pointer to the address of
the image, actual size and channels of the picture.</p>
<p>Take three channels as an example, the image is stored as an array of
"RGBRGBRGB...", each takes size of an 'unsigned char *'. Thus when we
want to get RGB at an intersection, we first calculate the index in the
image <code>(its.uv[0], its.uv[1]) -&gt; (x, y)</code>, then get the 1D
array location <code>ty * width + tx</code>, and times the number of
channels to get the actual location in the picture
<code>#channel * (ty * width + tx)</code>. Also, for 4 channels images,
if we tell <code>stbi_load</code> that we just want 3 channels, it will
give us the array of "RGBRGBRGB..." but not "RGBARGBA..."</p>
<p>What needs to be noted is that sRGB and linearRGB are different. So
we need to use <a
target="_blank" rel="noopener" href="https://www.pbr-book.org/3ed-2018/Texture/Image_Texture">color
correction</a></p>
<p><strong>Validation</strong></p>
<p>We use the UV mapping in blender to generate correct texture
coordinates and export it, then test it in our renderer.</p>
<ol type="1">
<li>Square picture</li>
</ol>
<p>The upper one is rendered by Blender. The texture picture is a
4-channel "color.png"</p>
<p><img src="../../images/text_ref.png" /><img
src="../../images/text.png" /></p>
<ol start="2" type="1">
<li>Rectengular picture</li>
</ol>
<p>The upper one is rendered by Blender. The texture picture is a
3-channel "blue.jpg"</p>
<p><img src="../../images/textrec_ref.png" /><img
src="../../images/textrec.png" /></p>
<h1 id="feature-3-homogeneous-media">Feature 3 Homogeneous media</h1>
<p><strong>Description</strong></p>
<p>There are many ways to implement homogeneous participating media. We
use the simplest one: free path sampling. When travelling in the media,
the ray has a probability that continue to travel, or scatter (which
means the next interaction happens).</p>
<p>If we don't consider the emission, the volume rendering equation is
like this:</p>
<p><code>$$ \begin&#123;aligned&#125; L(\mathbf&#123;x&#125;, \vec&#123;\omega&#125;) &amp;=T_&#123;r&#125;\left(\mathbf&#123;x&#125;, \mathbf&#123;x&#125;_&#123;z&#125;\right) L\left(\mathbf&#123;x&#125;_&#123;z&#125;, \vec&#123;\omega&#125;\right) \\ &amp;+\int_&#123;0&#125;^&#123;z&#125; T_&#123;r&#125;\left(\mathbf&#123;x&#125;, \mathbf&#123;x&#125;_&#123;t&#125;\right) \sigma_&#123;s&#125;\left(\mathbf&#123;x&#125;_&#123;t&#125;\right) \int_&#123;S^&#123;2&#125;&#125; f_&#123;p&#125;\left(\mathbf&#123;x&#125;_&#123;t&#125;, \vec&#123;\omega&#125;^&#123;\prime&#125;, \vec&#123;\omega&#125;\right) L_&#123;i&#125;\left(\mathbf&#123;x&#125;_&#123;t&#125;, \vec&#123;\omega&#125;^&#123;\prime&#125;\right) d \vec&#123;\omega&#125;^&#123;\prime&#125; d t \end&#123;aligned&#125; $$</code></p>
<p>Where <code>$L\left(\mathbf&#123;x&#125;_&#123;z&#125;, \vec&#123;\omega&#125;\right)$</code> is
the radiance background surface radiance, and the second term is the
accumulated in-scattered radiance. We calculate the integral by
Monte-Carlo method, where the integral over distance <span
class="math inline">\(\int_0^z ... dt\)</span> we use the free path
sampling to get the probability of how long the ray travels, and the
integral over solid angle <span
class="math inline">\(\int_{S^2}...d\omega\)</span> we use the phase
function to give the next direction and corresponding probability. I use
the graph below to show my path tracer. I assume that there is no
emitter inside the medium</p>
<p><img src="../../images/homo.jpg" /></p>
<p><strong>Design choice</strong></p>
<p>As the figure shows, we need to consider different situations. I will
follow the code logic to explain each of them. In my implementation the
ray has a record of the medium it is passing by, and there is only one
because I don't consider nested medium.</p>
<p>We have a throughput <span class="math inline">\(\beta\)</span>. The
ray begins to find the intersection.</p>
<p>It may hit the emitter (which is not shown here). Like other path
tracer, if this ray is directly from the eye or last bounce there is no
direct illumination, we add <span class="math inline">\(\beta
L_e\)</span>.</p>
<p>If it hits a mesh that does not have BSDF and the normal shows the
ray is outside this mesh (black ray (2)), we think it's about to go into
the volume, so we change the media of the ray
<code>&lt;highlight ray.media = its.mesh-&gt;getMedium()&gt;</code> and
change its source <code>ray.o = its.p</code> and <code>maxt</code> to
the intersection, continue to find the intersection. After this process
we see it as a new ray. If after this we find the ray does not have
<code>media</code> and the intersection (maybe the new intersection)
does not have a <code>BSDF</code>, some tricky case happens, e.g. two
boundaries are tangent to each other and too close, we just stop.</p>
<p>If we find the ray does not have media (purple ray (1)), we are
happy. We just need to use the normal direct illumination and mark the
variable <code>direct</code> as <code>true</code>.</p>
<p>However, when we are checking if the shadow ray is blocked in
situation (1), we need to consider the medium the ray passes by (green
ray (3)). If the ray just travels through it and there is no other mesh
in the way, we add the radiance of the emitter <span
class="math inline">\(\beta L_e\)</span> multiplied by an attenuation
term <span class="math inline">\(T_r\)</span> and the probability
<code>pdf</code> that this ray will not scatter (in our homogeneous
case, <code>pdf</code> = <span class="math inline">\(e^{-\sigma _t
t}\)</span> where <span class="math inline">\(t\)</span> is the distance
the ray stays in the medium).</p>
<p>If the ray has media. We need to sample the free path first. If our
sampled distance is less than that between the ray source and the
intersection, scatter happens in the medium (orange ray (4)). The ray's
direction may be changed by the phase function and the throughput is
multiplied by <span class="math inline">\(T_r(t)\)</span> * <span
class="math inline">\(\sigma_s\)</span> * pf-&gt;eval(<span
class="math inline">\(\omega\)</span>) / (pdf_t * pdf_{<span
class="math inline">\(\omega&#39;\)</span>}). We can also apply the
direct illumination by take the attenuation and the pdf into
consideration.</p>
<p>If our sampled distance is greater than the distance between the ray
source and the intersection, we hit a mesh in the medium. If the mesh
has a BSDF (black ray (2)), we evaluate the BSDF and use it to get the
ray for next interaction. We can also consider direct illumination. If
the mesh does not has a BSDF but has a Medium, it means we hit the
boundary of the medium from inside. We just calculate the attenuation
and change the source and the max length of the ray and continue. In
this situation we don't change the value of <code>direct</code>, and
there is no scattering happens.</p>
<p>We still use Russian Roulette to stop the process.</p>
<p>I created a class called <code>Medium</code> and
<code>PhaseFunction</code>. <code>PhaseFunction</code> is just like
<code>BSDF</code> class, to sample the new direction and to get the
probability by inquiring by a <code>struct PFQueryRecord</code>. It is a
child of medium property, and in my case I only registered the
"isotropic" phase function. <code>Medium</code> is a child of mesh. The
instance of <code>Medium</code> can be created while parsing and the
<code>Mesh</code> it belongs to will have a pointer to it.
<code>Medium</code> has a method called <code>pdf</code> and I use it to
evaluate the probability that a ray can travel how long.</p>
<p>Different kinds of <code>Medium</code> can be registered. I created
the homogeneous one for the scene and the empty one for test.</p>
<p><strong>Validation</strong></p>
<ol type="1">
<li>Empty</li>
</ol>
<p>Empty medium is quite simple. Its <span
class="math inline">\(T_r\)</span> and <span
class="math inline">\(pdf\)</span> is just 1.f and the
<code>Sample</code> method just "forward" the ray in its direction.</p>
<p>The empty medium should generate exactly same figure as no medium. In
the picture we could see a line that shows the existence of bigger ball.
Because my renderer uses the intersection and its mesh's BSDF/Medium
pointer to determine the location of the ray, it does not handle the
case where the light and the boundary are almost tangent/interleaved
mesh and volume very well.</p>
<p>The upper is the scene rendered by Blender <code>cycles</code>.</p>
<p><img src="../../images/sphere_ref.png" /><img
src="../../images/sphere_empty.png" /></p>
<ol start="2" type="1">
<li>God ray test</li>
</ol>
<p>The upper is the scene rendered by Blender <code>cycles</code>. Both
renderer uses 1024 samples/pixel. There are still some problems
regarding how to determine what kind of interaction is, so the wall
cannot be too close to the volume. The difference may be because the
parameters are different.</p>
<p><img src="../../images/room_ref.png" /><img
src="../../images/room.png" /></p>
<p>The scene with and without fog: <img
src="../../images/withfog.png" /></p>
<ol start="3" type="1">
<li>Numerical validation?</li>
</ol>
<p>Sadly, I could not find a mathematical way to validate it. Though I
think I have considered all the situation, it seems to be a kind of
"single scattering" which is an incomplete method so not mathematically
perfect.</p>
<h1 id="feature-4-object-instancing">Feature 4 Object instancing</h1>
<p><strong>Description</strong></p>
<p>I need to generate tens of thousands of grass and leaves. Though the
mesh is small, thousands of objects and the instance of their
BSDF/Medium is really a burden to memory. Therefore, we can use object
instancing to give each of these repeated objects a pointer that points
to a real object, but they themselves are a new kind of class that only
contains a pointer and the transform matrix, and its own bounding box.
As for BSDF (it can be independent but in my case it is a nullptr) and
vertices position information, it only use those of its parent. By this,
we avoid use up the memory. By modifying the exporting script for
Blender, it will not export the <code>.obj</code> file for those
"children" objects but only their transform.</p>
<p><strong>Design choice</strong></p>
<p>I design a new class inherited from the <code>Mesh</code> class
called <code>TransformedMesh</code>, that has all its vertex matrix/uv
matrix/BSDF... empty, except for a transform matrix, a pointer to its
parent, and a bounding box of its real location. When we want to inquire
its member, such as BSDF, or a position of a point, it calls the
corresponding method of its parent, and if needed, add a transform to
it. The information that needs to be transformed directly includes:
<code>surfaceArea</code>, <code>totalArea</code>,
<code>getBoundingBox</code>. For methods that need to get the position
and ray intersection, we do not change it directly, because we handle it
in the accelerating structure.</p>
<p>This new class is a registered <code>NoriObject</code>, which is
called <code>tmesh</code>. Each <code>TransformedMesh</code> is a child
of <code>WavefrontOBJ</code> it is binded to, the easiest way to
establish this relationship is to let the <code>tmesh</code> be children
of the <code>obj</code> in the <code>.xml</code> file, and while parsing
the file, we can add the parent pointer to child and load the transform
matrix of child. Type <code>tmesh</code> can only be child of
<code>mesh</code>, otherwise the program will complain about "Segment
Fault" when the null pointer of <code>tmesh</code> calls its methods. We
also get the bounding box of child at the very first, because building
the acceleration structure needs all of the meshes and their bounding
boxes. We should use a vector to record each child of an
<code>obj</code> Mesh, and when its <code>Scene</code> is adding child,
the Mesh should tell the Scene there are more <code>tmesh</code> meshes.
To save memory, we empty this vector after that.</p>
<p>When doing ray intersection, it is important to note that we cannot
return a temporary reference inside a function, and that's why I need to
apply transform in the <code>accel.cpp</code> but not the methods of
<code>TransformedMesh</code> itself. The bounding box of each
<code>tmesh</code> should be its real position because when we are
looking for intersection, we must ensure the <code>ray.maxt</code> is
updated correctly. When we are using the <code>RayIntersect()</code>
method of <code>Mesh</code> (but not <code>Accel</code>), we should
transform the ray to the corresponding ray for the "parent" mesh, so an
inverse transform is applied. After finding the intersection, we only
need to apply the transform to its intersection position, the distance
between ray source and the intersection point, its geometry normal and
shading normal. For a normal <code>mesh</code>, the transform will also
be applied, but it is an identity transform.</p>
<p>For the Blender part, first I need to design a simple mesh like grass
or leaf, and use the "particle system" in Blender to generate tens of
thousands of them, use the "weight mode" to adjust the distribution of
grass and leaves. These objects have a parent object and Blender records
the transform that each of them apply to the origin parent object.</p>
<p>Then I need to change the exporting file for Blender
<code>io_nori.py</code> to <code>io_nori_matrix.py</code>, because it's
meaningless to export so many meshes that will not be loaded by nori.
Thanks to the <code>matrix_world</code> API of <code>bpy</code>, we can
use it to get the transform of each "child" object with respect to its
parent. To distinguish between "parent" and "child" object, I set the
transform of all "parent" objects, i.e. objects that should be exported
as type "obj" to be identity (using "Apply all the transform" in
Blender), and keep the transform of "child" objects, i.e. objects that
should be exported as type "tmesh". While exporting, check if the
transform of the objects is identity. If yes, write the ".obj" file,
otherwise only write its transform to the ".xml" file. A tricky part
here is that the transform matrix should be transformed itself due to
the <code>nori</code>'s strange perspective, which has a coordinate of
(x, -z, y). From linear algebra we know the transform we need is a <span
class="math inline">\(4 \times 4\)</span> matrix</p>
<p><code>$$  P =  \begin&#123;bmatrix&#125; 1 &amp;  &amp;  &amp; \\   &amp;  &amp; -1 &amp; \\   &amp; 1 &amp;  &amp; \\   &amp;  &amp;  &amp; 1 \end&#123;bmatrix&#125;  $$</code></p>
<p>and we apply it to the matrix we get from <code>matrix_world</code>
<span class="math inline">\(T\)</span></p>
<p><code>$$ P^&#123;\top&#125;TP $$</code></p>
<p>Then we can get a correct transform matrix, and the export plugin
will generate a <code>tmesh</code> object like this</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mesh</span> <span class="attr">type</span>=<span class="string">&quot;tmesh&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span> <span class="attr">name</span>=<span class="string">&quot;filename&quot;</span> <span class="attr">value</span>=<span class="string">&quot;meshes/big.obj&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">transform</span> <span class="attr">name</span>=<span class="string">&quot;toWorld&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">matrix</span> <span class="attr">value</span>=<span class="string">&quot;1.5,0.0,0.0,0.0,0.0,1.5,0.0,0.0,0.0,0.0,1.5,1.0,0.0,0.0,0.0,1.0&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">transform</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mesh</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>I haven't figured out how to make the "tmesh" to be the child of
"obj" when exporting, so after generating all the <code>obj</code> and
<code>tmesh</code> mesh description, we should manually move the tmesh
part into its corrsponding parent, like this:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mesh</span> <span class="attr">type</span>=<span class="string">&quot;obj&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">string</span> <span class="attr">name</span>=<span class="string">&quot;filename&quot;</span> <span class="attr">value</span>=<span class="string">&quot;meshes/small.obj&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bsdf</span> <span class="attr">type</span>=<span class="string">&quot;diffuse&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">&quot;albedo&quot;</span> <span class="attr">value</span>=<span class="string">&quot;0.800000011920929,0.800000011920929,0.800000011920929&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bsdf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mesh</span> <span class="attr">type</span>=<span class="string">&quot;tmesh&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">string</span> <span class="attr">name</span>=<span class="string">&quot;filename&quot;</span> <span class="attr">value</span>=<span class="string">&quot;meshes/big.obj&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">transform</span> <span class="attr">name</span>=<span class="string">&quot;toWorld&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">matrix</span> <span class="attr">value</span>=<span class="string">&quot;1.5,0.0,0.0,0.0,0.0,1.5,0.0,0.0,0.0,0.0,1.5,1.0,0.0,0.0,0.0,1.0&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">transform</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mesh</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mesh</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="../../images/grassland.png" /></p>
<p><strong>Validation</strong></p>
<ol type="1">
<li>Two objects vs one object with a transformed tmesh</li>
</ol>
<p>In blender the real scence is like this:</p>
<p><img src="../../images/sphere_blender.png" /></p>
<p>where the big ball has a transform of scale and displacement in y
direction with respect to the small one, and the small ball has applied
all the transform (identity matrix).</p>
<p>We use the example above to render using two objects (small.obj &amp;
big.obj) or only use the small ball and a transform of it.</p>
<p>We can get the same output</p>
<p><img src="../../images/sphere_two.png" /><img
src="../../images/sphere_one.png" /></p>
<p>The actual transform is that the big ball is twice the size of small
ball, and then translate 1.5m in the negative direction of the y-axis.
However, from the transform matrix we could see the translation is at z
axis and changes the sign. We should also note that when apply transform
in Blender, the parent object's transform should be applied at first,
otherwise the matrix we get is not correct.</p>
<ol start="2" type="1">
<li>Memory usage</li>
</ol>
<p>when rendering my final scene. I have 53000 "grass", 3500
"leave_origin", 10000 "furry", 3000 "shrub_sorrel_01_d", 3000
"shrub_sorrel_01_b", 1000 "Grashalm.002" and other meshes, so the
roughly memory should be about 8.3 G only for mesh itself.</p>
<p><img src="../../images/instance.png" /></p>
<p>The constructing of BVH uses up to 13.7 GB.</p>
<p><img src="../../images/bvh.png" /></p>
<p>From the <code>ps v</code> command, we could see the memory used at
constructing stage (11 GB) and rendering stage (4.7 GB):</p>
<p><img src="../../images/memory_peak.png" /></p>
<p><img src="../../images/memory_render.png" /></p>
<p>Therefore the object instancing works.</p>
<h1 id="碎碎念">碎碎念</h1>
<p>Before this course I didn't know coding and art can be so perfectly
integrated. The course is soooooo interesting and the professor &amp;
TAs are insightful and helpful.
虽然我在反思，对我来说到底是Blender还是CG中的物理数学概率知识更有意思，否则的话怎么hack
point都不做.... Anyway，stay determined, Axiwa! 👩‍💻</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2023/04/02/cs440/">
    <time datetime="2023-04-01T16:00:00.000Z" class="entry-date">
        2023-04-02
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Project/">Project</a>
  </div>

    
    </footer>
</article>


    
<nav class="nav-single">
    <h3 class="assistive-text">文章导航</h3>
    
        <span class="nav-previous"><a href="/2023/06/17/coc/" rel="prev"><span class="meta-nav">←</span> 跑团Replay观看记录</a></span>
    
    
        <span class="nav-next"><a href="/2023/04/02/hair/" rel="next">Hair Rendering <span class="meta-nav">→</span></a></span>
    
</nav><!-- .nav-single -->







</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-graphics/">Computer graphics</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Debug/">Debug</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Knowledge/">Knowledge</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Lecture-notes/">Lecture notes</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/">Project</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%9B%E4%BD%9C/">创作</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BA%9F%E8%AF%9D/">废话</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%A9/">玩</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%B7%91%E5%9B%A2/">跑团</a><span class="category-list-count">1</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2024/01/27/story/">故事</a>
          </li>
        
          <li>
            <a href="/2023/06/19/diary/">正经人谁写日记啊</a>
          </li>
        
          <li>
            <a href="/2023/06/17/coc/">跑团Replay观看记录</a>
          </li>
        
          <li>
            <a href="/2023/04/02/cs440/">CS440 Rendering Engine</a>
          </li>
        
          <li>
            <a href="/2023/04/02/hair/">Hair Rendering</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  
    
  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2024 Axiwa
    All rights reserved.</p>
    <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</footer>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/js/share.js'];</script>

<script src="/js/jquery-3.3.1.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>